K-Nearest Neighbors (K-NN) є одним з простих і популярних алгоритмів машинного навчання для класифікації і регресії. Основна ідея полягає в тому, що вхідний зразок класифікується за допомогою ближайших до нього зразків з тренувального набору даних.

Основні переваги K-NN:

    Простота реалізації та інтерпретації. K-NN є дуже простим алгоритмом, який не вимагає складної математики та великої кількості обчислень, тому його можна легко реалізувати та використовувати.

    Не потрібна тренувальна фаза. Оскільки K-NN не будує жодної моделі, для його використання не потрібно проводити тренувальну фазу. Це означає, що алгоритм може працювати з великими обсягами даних без значної затримки.

    Висока точність для деяких видів даних. K-NN може бути дуже точним для деяких видів даних, особливо для даних з високою кількістю ознак та достатньою кількістю даних.

Основні недоліки K-NN:

    Швидкість передбачення. K-NN може бути повільним для великих тренувальних наборів даних, оскільки для класифікації кожного зразка потрібно порівняти його з кожним зразком в тренувальному наборі.

    Чутливість до шуму та нерівномірності розподілу даних. K-NN може бути дуже чутливим до шуму та нерівномірності розподілу даних, що може призвести до неправильної класифікації.

    Перенавчання. Якщо значна частина даних з тренувального набору належить до однієї категорії, то







Регуляризація — це техніка, яка використовується в машинному навчанні для запобігання переобладнанню, яке відбувається, коли модель вчиться підлаштовуватися під навчальні дані занадто точно, що призводить до поганого узагальнення нових даних. Регуляризація працює шляхом додавання штрафного терміну до функції вартості, яку модель намагається мінімізувати, заохочуючи її вибирати простіші моделі, які краще узагальнюють.

У випадку логістичної регресії регуляризацію можна застосувати шляхом додавання штрафного терміну до функції витрат, яка вимірює складність моделі. Дві форми регуляризації, які найчастіше використовуються для логістичної регресії, це регулярізація L1 (також відома як регулярізація Лассо) і регулярізація L2 (також відома як регулярізація Ріджа).

Регулярізація L1 додає штрафний термін, пропорційний абсолютним значенням коефіцієнтів моделі логістичної регресії. Це має ефект скорочення деяких коефіцієнтів до нуля, фактично усуваючи деякі функції з моделі. Регулярізація рівня L1 корисна, коли в даних є багато характеристик, і існує підозра, що лише невелика їх підмножина має відношення до результату.

Регулярізація L2 додає штрафний термін, який пропорційний квадрату коефіцієнтів моделі логістичної регресії. Це призводить до зменшення всіх коефіцієнтів до нуля, але не обов’язково до нуля. Регулярізація рівня L2 корисна, коли підозрюється, що всі функції в даних є релевантними, але модель переобладнана через високу дисперсію в даних.

Налаштувавши параметр регуляризації, можна контролювати ступінь застосованої регуляризації, виходячи зі складності моделі та придатності даних. Регуляризація є важливою технікою для покращення ефективності узагальнення моделей логістичної регресії, і вона широко використовується на практиці.